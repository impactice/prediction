# prediction


## ver1 

```
import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Input # Input ì¶”ê°€ë¨
import sys
import os

# ë¶ˆí•„ìš”í•œ ê²½ê³  ë©”ì‹œì§€ ë„ê¸° (ê¹”ë”í•œ í™”ë©´ì„ ìœ„í•´)
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
import warnings
warnings.filterwarnings('ignore')

# --- 1. ë°ì´í„° ì¤€ë¹„ ---
print("ğŸ“‚ ë¡œë˜ ë°ì´í„°ë¥¼ ì½ì–´ì˜µë‹ˆë‹¤...")

def read_csv_safe(filename):
    try:
        return pd.read_csv(filename, encoding='utf-8', header=None)
    except UnicodeDecodeError:
        return pd.read_csv(filename, encoding='cp949', header=None)

try:
    df1 = read_csv_safe('ë‹¹ì²¨(1~600).csv')
    df2 = read_csv_safe('ë‹¹ì²¨(601~1203).csv')
    
    data1 = df1.iloc[3:]
    data2 = df2.iloc[3:]
    full_df = pd.concat([data2, data1], axis=0)
    full_df = full_df[[1, 13, 14, 15, 16, 17, 18]]
    full_df.columns = ['Round', 'Num1', 'Num2', 'Num3', 'Num4', 'Num5', 'Num6']
    full_df = full_df.apply(pd.to_numeric, errors='coerce').dropna()
    full_df = full_df.sort_values('Round').reset_index(drop=True)
    
    numbers = full_df[['Num1', 'Num2', 'Num3', 'Num4', 'Num5', 'Num6']].values
    scaled_numbers = numbers / 45.0
    
    window_size = 5
    
    def create_dataset(data, window_size):
        X, y = [], []
        for i in range(len(data) - window_size):
            X.append(data[i : i + window_size])
            y.append(data[i + window_size])
        return np.array(X), np.array(y)
        
    X, y = create_dataset(scaled_numbers, window_size)
    last_window = scaled_numbers[-window_size:]
    last_window = last_window.reshape((1, window_size, 6))

    print(f"âœ… ë°ì´í„° ì½ê¸° ì„±ê³µ! ì´ {len(full_df)}íšŒì°¨ ë°ì´í„°ë¥¼ í™•ë³´í–ˆìŠµë‹ˆë‹¤.")

except Exception as e:
    print(f"\nâŒ [ì˜¤ë¥˜] ë°ì´í„°ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
    sys.exit()

# --- 2. 5ëª…ì˜ AI í•™ìŠµ ì‹œì‘ ---
print(f"\nğŸš€ 5ê°œì˜ ì„œë¡œ ë‹¤ë¥¸ AI ëª¨ë¸ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤... (ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”)")
print("=" * 60)

labels = ['A', 'B', 'C', 'D', 'E']

for i in range(5):
    print(f"\nğŸ¤– [AI ëª¨ë¸ {labels[i]} í•™ìŠµ ì¤‘...]")
    
    # ì—¬ê¸°ì„œ ê²½ê³ ë¥¼ ì—†ì• ê¸° ìœ„í•´ 'Input' ì¸µì„ ë”°ë¡œ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤.
    model = Sequential([
        Input(shape=(window_size, 6)), # ìµœì‹  ë°©ì‹
        LSTM(64, activation='relu'),
        Dense(6)
    ])
    model.compile(optimizer='adam', loss='mse')
    
    # í•™ìŠµ (verbose=0ìœ¼ë¡œ ì§€ì €ë¶„í•œ ë¡œê·¸ ìˆ¨ê¹€)
    model.fit(X, y, epochs=100, batch_size=16, verbose=0)
    
    prediction = model.predict(last_window, verbose=0)
    
    pred_nums = prediction * 45.0
    pred_nums = np.round(pred_nums).flatten().astype(int)
    pred_nums = np.clip(pred_nums, 1, 45)
    
    unique_nums = np.unique(pred_nums)
    while len(unique_nums) < 6:
        new_num = np.random.randint(1, 46)
        if new_num not in unique_nums:
            unique_nums = np.append(unique_nums, new_num)
    
    final_nums = np.sort(unique_nums)
    print(f"ğŸ‘‰ Game {labels[i]} ì¶”ì²œ ë²ˆí˜¸: {final_nums}")

print("\n" + "=" * 60)
input("âœ… ëª¨ë“  ì˜ˆì¸¡ì´ ëë‚¬ìŠµë‹ˆë‹¤. ì¢…ë£Œí•˜ë ¤ë©´ ì—”í„° í‚¤ë¥¼ ëˆ„ë¥´ì„¸ìš”...")
```


## ver2

### ì–‘ë°©í–¥(Bidirectional) LSTM ì‚¬ìš©:
ê¸°ì¡´: ê³¼ê±° $\rightarrow$ ë¯¸ë˜ ìˆœì„œë¡œë§Œ ê³µë¶€í–ˆìŠµë‹ˆë‹¤.  
ì—…ê·¸ë ˆì´ë“œ: ë¬¸ë§¥ì„ ë” ì˜ íŒŒì•…í•˜ê¸° ìœ„í•´ (ê³¼ê±° $\rightarrow$ ë¯¸ë˜)ì™€ (ë¯¸ë˜ $\rightarrow$ ê³¼ê±°) ì–‘ìª½ ë°©í–¥ìœ¼ë¡œ ë°ì´í„°ë¥¼ í›‘ì–´ë³´ê²Œ ë§Œë“­ë‹ˆë‹¤. (ë§ˆì¹˜ ì˜ì–´ ë…í•´ë¥¼ í•  ë•Œ ì•ë’¤ ë¬¸ë§¥ì„ ë‹¤ ë³´ëŠ” ê²ƒê³¼ ê°™ìŠµë‹ˆë‹¤.)

### ì¸µ(Layer) ë” ìŒ“ê¸° (Deep Learning):
ê¸°ì¡´: ë‡Œì„¸í¬ ì¸µì´ 1ê°œì˜€ìŠµë‹ˆë‹¤.  
ì—…ê·¸ë ˆì´ë“œ: LSTM ì¸µì„ 2~3ê°œë¡œ ê²¹ì³ì„œ ìŒ“ìŠµë‹ˆë‹¤. 1ì¸µì€ ë‹¨ìˆœí•œ íŒ¨í„´, 2ì¸µì€ ë³µì¡í•œ íŒ¨í„´ì„ ë¶„ì„í•˜ë„ë¡ **"ê¹Šì€ ì‚¬ê³ "**ë¥¼ í•˜ê²Œ ë§Œë“­ë‹ˆë‹¤.

### í•™ìŠµ íšŸìˆ˜ì™€ ë‡Œì„¸í¬ ëŠ˜ë¦¬ê¸°:
ê¸°ì¡´ 64ê°œì˜€ë˜ ë‰´ëŸ°(Neuron)ì„ 128ê°œ ë˜ëŠ” 256ê°œë¡œ ëŠ˜ë¦¬ê³ , í•™ìŠµ ë°˜ë³µ íšŸìˆ˜(Epoch)ë„ ëŠ˜ë ¤ì„œ ë” ì§‘ìš”í•˜ê²Œ íŒ¨í„´ì„ ì°¾ê²Œ í•©ë‹ˆë‹¤.

```
import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Input, Bidirectional, Dropout
import sys
import os

# 1. í™˜ê²½ ì„¤ì •
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
import warnings
warnings.filterwarnings('ignore')

print("ğŸ“‚ [Proë²„ì „] ë³€ê²½ëœ ë°ì´í„° êµ¬ì¡°ì— ë§ì¶° ë¡œë”© ì¤‘ì…ë‹ˆë‹¤...")

# 2. ë°ì´í„° ì½ê¸°
def read_csv_safe(filename):
    try:
        return pd.read_csv(filename, encoding='utf-8', header=None)
    except UnicodeDecodeError:
        return pd.read_csv(filename, encoding='cp949', header=None)

try:
    df1 = read_csv_safe('ë‹¹ì²¨(1~600).csv')
    df2 = read_csv_safe('ë‹¹ì²¨(601~1203).csv')
    
    # 3ì¤„ í—¤ë” ê±´ë„ˆë›°ê¸° (ì´ê±´ êµ¬ì¡°ê°€ ìœ ì§€ë˜ì—ˆìœ¼ë¯€ë¡œ ê·¸ëŒ€ë¡œ ë‘¡ë‹ˆë‹¤)
    data1 = df1.iloc[3:]
    data2 = df2.iloc[3:]
    
    full_df = pd.concat([data2, data1], axis=0)
    
    # ğŸ”¥ [í•µì‹¬ ìˆ˜ì •] ë³€ê²½ëœ íŒŒì¼ ë‚´ìš©ì— ë§ê²Œ ì—´ ë²ˆí˜¸ ìˆ˜ì • ğŸ”¥
    # ê¸°ì¡´: [1, 13, 14, 15, 16, 17, 18]
    # ë³€ê²½: [1, 2, 3, 4, 5, 6, 7] (ë¹ˆ ì¹¸ ì—†ì´ ë°”ë¡œ ì˜†ì— ë¶™ì–´ ìˆìŒ)
    full_df = full_df[[1, 2, 3, 4, 5, 6, 7]]
    
    full_df.columns = ['Round', 'Num1', 'Num2', 'Num3', 'Num4', 'Num5', 'Num6']
    full_df = full_df.apply(pd.to_numeric, errors='coerce').dropna()
    full_df = full_df.sort_values('Round').reset_index(drop=True)
    
    # ì •ê·œí™”
    numbers = full_df[['Num1', 'Num2', 'Num3', 'Num4', 'Num5', 'Num6']].values
    scaled_numbers = numbers / 45.0
    
    window_size = 10 
    
    def create_dataset(data, window_size):
        X, y = [], []
        for i in range(len(data) - window_size):
            X.append(data[i : i + window_size])
            y.append(data[i + window_size])
        return np.array(X), np.array(y)
        
    X, y = create_dataset(scaled_numbers, window_size)
    last_window = scaled_numbers[-window_size:]
    last_window = last_window.reshape((1, window_size, 6))

    print(f"âœ… ë°ì´í„° ë¡œë”© ì„±ê³µ! ì´ {len(full_df)}íšŒì°¨ (ì—´ êµ¬ì¡° ìë™ ë³´ì • ì™„ë£Œ)")
    print(f"âœ… ë¶„ì„ ê¹Šì´: ê³¼ê±° {window_size}íšŒì°¨ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì˜ˆì¸¡")

except Exception as e:
    print(f"\nâŒ ë°ì´í„° êµ¬ì¡° ì˜¤ë¥˜: {e}")
    print("ğŸ‘‰ ì—‘ì…€ ë‚´ìš©ì´ ë°”ë€Œë©´ì„œ ì—´ ë²ˆí˜¸ê°€ ë‹¬ë¼ì§„ ê²ƒ ê°™ìŠµë‹ˆë‹¤. íŒŒì¼ ë‚´ìš©ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    sys.exit()

# 3. ê³ ì„±ëŠ¥ AI ëª¨ë¸ ì„¤ê³„ (ê²€ì‚¬ ë°©ë²• ë³€ê²½ X)
print(f"\nğŸš€ [Deep Learning] ê³ ì„±ëŠ¥ ì˜ˆì¸¡ ëª¨ë¸ ê°€ë™ ì‹œì‘...")
print("=" * 60)

labels = ['A', 'B', 'C', 'D', 'E']

for i in range(5):
    print(f"\nğŸ§  [AI ëª¨ë¸ {labels[i]} ì‹¬ì¸µ í•™ìŠµ ì¤‘...]")
    
    model = Sequential([
        Input(shape=(window_size, 6)),
        # ì–‘ë°©í–¥ LSTM
        Bidirectional(LSTM(128, return_sequences=True)),
        Dropout(0.2),
        # ì‹¬ì¸µ LSTM
        LSTM(64, return_sequences=False),
        Dropout(0.2),
        # ê²°ê³¼ ì¶œë ¥
        Dense(64, activation='relu'),
        Dense(6)
    ])
    
    model.compile(optimizer='adam', loss='mse')
    
    # í•™ìŠµ (150íšŒ ë°˜ë³µ)
    model.fit(X, y, epochs=150, batch_size=16, verbose=0)
    
    # ì˜ˆì¸¡
    prediction = model.predict(last_window, verbose=0)
    
    pred_nums = prediction * 45.0
    pred_nums = np.round(pred_nums).flatten().astype(int)
    pred_nums = np.clip(pred_nums, 1, 45)
    
    unique_nums = np.unique(pred_nums)
    while len(unique_nums) < 6:
        new_num = np.random.randint(1, 46)
        if new_num not in unique_nums:
            unique_nums = np.append(unique_nums, new_num)
    
    final_nums = np.sort(unique_nums)
    print(f"ğŸ‘‰ Game {labels[i]} (Deep) ì¶”ì²œ: {final_nums}")

print("\n" + "=" * 60)
input("âœ… ê³ ì„±ëŠ¥ ì˜ˆì¸¡ ì™„ë£Œ. ì¢…ë£Œí•˜ë ¤ë©´ ì—”í„° í‚¤ë¥¼ ëˆ„ë¥´ì„¸ìš”...")
```
- íŒŒì¼ ëª¨ìŠµë„ ë³€ê²½ì´ ë˜ì—ˆìŒ 


## ver3
Window Sizeë¥¼ 260(ì•½ 5ë…„ì¹˜)ë¥¼ ë³´ê³  ì˜ˆì¸¡
```
import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Input, Bidirectional, Dropout
import sys
import os

# 1. í™˜ê²½ ì„¤ì •
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
import warnings
warnings.filterwarnings('ignore')

print("ğŸ“‚ [Ultra Long-Term] ê³¼ê±° 260íšŒ(ì•½ 5ë…„) ë°ì´í„°ë¥¼ í†µì§¸ë¡œ ë¶„ì„í•©ë‹ˆë‹¤...")

# 2. ë°ì´í„° ì½ê¸°
def read_csv_safe(filename):
    try:
        return pd.read_csv(filename, encoding='utf-8', header=None)
    except UnicodeDecodeError:
        return pd.read_csv(filename, encoding='cp949', header=None)

try:
    df1 = read_csv_safe('ë‹¹ì²¨(1~600).csv')
    df2 = read_csv_safe('ë‹¹ì²¨(601~1203).csv')
    
    # í—¤ë” 3ì¤„ ì œê±°
    data1 = df1.iloc[3:]
    data2 = df2.iloc[3:]
    
    full_df = pd.concat([data2, data1], axis=0)
    
    # ìˆ˜ì •ëœ íŒŒì¼ êµ¬ì¡° ë°˜ì˜ (1~7ì—´)
    full_df = full_df[[1, 2, 3, 4, 5, 6, 7]]
    full_df.columns = ['Round', 'Num1', 'Num2', 'Num3', 'Num4', 'Num5', 'Num6']
    full_df = full_df.apply(pd.to_numeric, errors='coerce').dropna()
    full_df = full_df.sort_values('Round').reset_index(drop=True)
    
    # ì •ê·œí™”
    numbers = full_df[['Num1', 'Num2', 'Num3', 'Num4', 'Num5', 'Num6']].values
    scaled_numbers = numbers / 45.0
    
    # ğŸ”¥ [í•µì‹¬ ë³€ê²½] Window Sizeë¥¼ 260(ì•½ 5ë…„)ìœ¼ë¡œ ì„¤ì • ğŸ”¥
    # ë„ˆë¬´ í¬ë©´(ì˜ˆ: 1000) í•™ìŠµí•  ë°ì´í„°ê°€ ë¶€ì¡±í•´ì§€ë¯€ë¡œ, 260 ì •ë„ê°€ ì ë‹¹í•œ 'ìµœëŒ€ì¹˜'ì…ë‹ˆë‹¤.
    window_size = 260
    
    def create_dataset(data, window_size):
        X, y = [], []
        for i in range(len(data) - window_size):
            X.append(data[i : i + window_size])
            y.append(data[i + window_size])
        return np.array(X), np.array(y)
        
    X, y = create_dataset(scaled_numbers, window_size)
    last_window = scaled_numbers[-window_size:]
    last_window = last_window.reshape((1, window_size, 6))

    print(f"âœ… ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ! ì´ {len(full_df)}íšŒì°¨")
    print(f"âœ… ë¶„ì„ ë²”ìœ„: í•œ ë²ˆì— ê³¼ê±° {window_size}ì£¼(ì•½ 5ë…„)ì˜ íë¦„ì„ ë´…ë‹ˆë‹¤.")
    print(f"âœ… í•™ìŠµ ê°€ëŠ¥ ì˜ˆì œ ìˆ˜: {len(X)}ê°œ (ì¶©ë¶„í•©ë‹ˆë‹¤!)")

except Exception as e:
    print(f"\nâŒ ì˜¤ë¥˜: {e}")
    sys.exit()

# 3. ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡
print(f"\nğŸš€ [Super Long-Term] 5ë…„ì¹˜ íŒ¨í„´ ì •ë°€ ë¶„ì„ ì‹œì‘...")
print("=" * 60)

labels = ['A', 'B', 'C', 'D', 'E']

for i in range(5):
    print(f"\nğŸ§  [AI ëª¨ë¸ {labels[i]} í•™ìŠµ ì¤‘... (ì‹œê°„ì´ ì¢€ ê±¸ë¦½ë‹ˆë‹¤)]")
    
    model = Sequential([
        Input(shape=(window_size, 6)),
        # 5ë…„ì¹˜ ê¸´ ë°ì´í„°ë¥¼ ê¹Œë¨¹ì§€ ì•Šê²Œ LSTM ë‰´ëŸ°ì„ 256ê°œë¡œ ëŒ€í­ ëŠ˜ë¦¼
        Bidirectional(LSTM(256, return_sequences=True)),
        Dropout(0.3),
        
        LSTM(128, return_sequences=False),
        Dropout(0.3),
        
        Dense(128, activation='relu'),
        Dense(6)
    ])
    
    model.compile(optimizer='adam', loss='mse')
    
    # ë°ì´í„°ê°€ ê¸¸ì–´ì„œ í•™ìŠµ íšŸìˆ˜(epochs)ë¥¼ 300íšŒë¡œ ì„¤ì •
    model.fit(X, y, epochs=300, batch_size=64, verbose=0)
    
    prediction = model.predict(last_window, verbose=0)
    
    pred_nums = prediction * 45.0
    pred_nums = np.round(pred_nums).flatten().astype(int)
    pred_nums = np.clip(pred_nums, 1, 45)
    
    unique_nums = np.unique(pred_nums)
    while len(unique_nums) < 6:
        new_num = np.random.randint(1, 46)
        if new_num not in unique_nums:
            unique_nums = np.append(unique_nums, new_num)
    
    final_nums = np.sort(unique_nums)
    print(f"ğŸ‘‰ Game {labels[i]} (5ë…„ ë¶„ì„) ì¶”ì²œ: {final_nums}")

print("\n" + "=" * 60)
input("âœ… ì˜ˆì¸¡ ì™„ë£Œ. ì¢…ë£Œí•˜ë ¤ë©´ ì—”í„° í‚¤ë¥¼ ëˆ„ë¥´ì„¸ìš”...")
```

## ver4 
### ì „ëµ ë³€ê²½: "ìˆ«ì ê³„ì‚°" $\rightarrow$ "í™•ë¥  ì„ íƒ" (Classification) 
ì´ì œë¶€í„°ëŠ” AIì—ê²Œ ìˆ«ìë¥¼ ê³„ì‚°í•˜ë¼ê³  í•˜ì§€ ì•Šê³ , "1ë²ˆë¶€í„° 45ë²ˆ ê³µ ì¤‘ì—ì„œ, ë‚˜ì˜¬ í™•ë¥ ì´ ê°€ì¥ ë†’ì€ ê³µ 6ê°œë¥¼ ê³¨ë¼ë´!"  
ê¸°ì¡´ ë°©ì‹ (íšŒê·€): "ë‹¤ìŒ ìˆ«ìëŠ” 23.4ì¼ ê±°ì•¼" $\rightarrow$ 23 (ì• ë§¤í•¨)  
ìƒˆë¡œìš´ ë°©ì‹ (ë¶„ë¥˜): "1ë²ˆ ê³µì´ ë‚˜ì˜¬ í™•ë¥  90%, 2ë²ˆ ê³µì€ 10%... ê·¸ëŸ¬ë‹ˆê¹Œ 1ë²ˆ ì¶”ì²œ!" (ë” ëª…í™•í•¨)  
ì´ ë°©ì‹ì€ ë°ì´í„° ê³¼í•™ì—ì„œ **ì›-í•« ì¸ì½”ë”©(One-Hot Encoding)**ì´ë¼ê³  ë¶€ë¥´ëŠ” ê³ ê¸‰ ê¸°ë²•ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. 
```
import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Input, Bidirectional, Dropout, BatchNormalization
import sys
import os

# 1. í™˜ê²½ ì„¤ì •
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
import warnings
warnings.filterwarnings('ignore')

print("ğŸ“‚ [Final Ver] í™•ë¥  ê¸°ë°˜(Classification) ì •ë°€ ë¶„ì„ ëª¨ë“œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")

# 2. ë°ì´í„° ì½ê¸°
def read_csv_safe(filename):
    try:
        return pd.read_csv(filename, encoding='utf-8', header=None)
    except UnicodeDecodeError:
        return pd.read_csv(filename, encoding='cp949', header=None)

try:
    df1 = read_csv_safe('ë‹¹ì²¨(1~600).csv')
    df2 = read_csv_safe('ë‹¹ì²¨(601~1203).csv')
    
    # í—¤ë” 3ì¤„ ì œê±° ë° í†µí•©
    data1 = df1.iloc[3:]
    data2 = df2.iloc[3:]
    full_df = pd.concat([data2, data1], axis=0)
    
    # ì—´ êµ¬ì¡° ì •ë¦¬
    full_df = full_df[[1, 2, 3, 4, 5, 6, 7]]
    full_df.columns = ['Round', 'Num1', 'Num2', 'Num3', 'Num4', 'Num5', 'Num6']
    full_df = full_df.apply(pd.to_numeric, errors='coerce').dropna()
    full_df = full_df.sort_values('Round').reset_index(drop=True)
    
    # --- ğŸ”¥ ì—¬ê¸°ê°€ ì™„ì „íˆ ë°”ë€ ë¶€ë¶„ì…ë‹ˆë‹¤ (ë°ì´í„° ê°€ê³µ) ğŸ”¥ ---
    # ë²ˆí˜¸ë¥¼ ê·¸ëŒ€ë¡œ ì“°ëŠ” ê²Œ ì•„ë‹ˆë¼, 45ê°œì˜ êµ¬ë©(One-Hot)ì„ ë§Œë“­ë‹ˆë‹¤.
    # ì˜ˆ: ë‹¹ì²¨ë²ˆí˜¸ê°€ 1, 3ì´ë©´ -> [1, 0, 1, 0, 0, ...] ì´ëŸ° ì‹ì˜ 0ê³¼ 1ë¡œ ëœ ë°”ì½”ë“œë¥¼ ë§Œë“­ë‹ˆë‹¤.
    
    # ë°ì´í„° ì „ì²´ë¥¼ 0~1ë¡œ ì •ê·œí™” (ì…ë ¥ìš©)
    numbers = full_df[['Num1', 'Num2', 'Num3', 'Num4', 'Num5', 'Num6']].values
    scaled_numbers = numbers / 45.0
    
    # ê²°ê³¼ê°’(Y)ì„ ìœ„í•œ ì›-í•« ì¸ì½”ë”© í•¨ìˆ˜
    def numbers_to_onehot(rows):
        # 46ê°œì§œë¦¬ ë¹ˆ ë°°ì—´(0ë²ˆ ì¸ë±ìŠ¤ëŠ” ì•ˆ ì”€)
        onehot = np.zeros((len(rows), 46))
        for i, row in enumerate(rows):
            for num in row:
                onehot[i, int(num)] = 1 # í•´ë‹¹ ë²ˆí˜¸ ìë¦¬ì— 1 í‘œì‹œ
        return onehot[:, 1:] # 0ë²ˆ ì¸ë±ìŠ¤ ì œì™¸í•˜ê³  1~45ë²ˆë§Œ ë°˜í™˜

    # ìœˆë„ìš° ì„¤ì • (í™•ë¥  ëª¨ë¸ì€ ë„ˆë¬´ ê¸¸ë©´ ì˜¤íˆë ¤ í—·ê°ˆë ¤í•´ì„œ 50ì£¼ ì •ë„ê°€ ì ë‹¹í•¨)
    window_size = 50
    
    def create_dataset(raw_data, window_size):
        X, y = [], []
        # raw_dataëŠ” ì…ë ¥ìš© ì •ê·œí™” ë°ì´í„°
        # ì‹¤ì œ ë²ˆí˜¸ëŠ” one-hot íƒ€ê²Ÿìš©ìœ¼ë¡œ ë‹¤ì‹œ ê°€ì ¸ì˜´
        real_numbers = full_df[['Num1', 'Num2', 'Num3', 'Num4', 'Num5', 'Num6']].values
        
        for i in range(len(raw_data) - window_size):
            X.append(raw_data[i : i + window_size])
            # yê°’ì€ "ë‹¤ìŒ íšŒì°¨ ë²ˆí˜¸ë“¤ì˜ ë°”ì½”ë“œ(One-Hot)"ê°€ ë¨
            y.append(real_numbers[i + window_size])
            
        return np.array(X), np.array(y)
        
    X, y_indices = create_dataset(scaled_numbers, window_size)
    # yë¥¼ ì›-í•« ì¸ì½”ë”©ìœ¼ë¡œ ë³€í™˜ (í™•ë¥  ê³„ì‚°ìš© ì •ë‹µì§€)
    y = numbers_to_onehot(y_indices) 
    
    last_window = scaled_numbers[-window_size:]
    last_window = last_window.reshape((1, window_size, 6))

    print(f"âœ… ë°ì´í„° ë³€í™˜ ì™„ë£Œ: 'ìˆ«ì ì˜ˆì¸¡'ì´ ì•„ë‹Œ 'í™•ë¥  ë¶„ì„' í˜•íƒœë¡œ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤.")

except Exception as e:
    print(f"\nâŒ ì˜¤ë¥˜: {e}")
    sys.exit()

# 3. í™•ë¥  ì˜ˆì¸¡ ëª¨ë¸ ì„¤ê³„
print(f"\nğŸš€ [Probability Model] 1~45ë²ˆ ê³µ ê°ê°ì˜ ì¶œí˜„ í™•ë¥ ì„ ê³„ì‚°í•©ë‹ˆë‹¤...")
print("=" * 60)

labels = ['A', 'B', 'C', 'D', 'E']

for i in range(5):
    print(f"\nğŸ§  [AI ëª¨ë¸ {labels[i]} í•™ìŠµ ì¤‘...]")
    
    model = Sequential([
        Input(shape=(window_size, 6)),
        
        # íŒ¨í„´ ë¶„ì„
        Bidirectional(LSTM(128, return_sequences=True)),
        Dropout(0.3),
        BatchNormalization(), # í•™ìŠµ ì•ˆì •í™” ê¸°ìˆ  ì¶”ê°€
        
        LSTM(64, return_sequences=False),
        Dropout(0.3),
        BatchNormalization(),
        
        Dense(128, activation='relu'),
        
        # ğŸ”¥ ì¶œë ¥ì¸µ ë³€ê²½: 1ê°œì˜ ìˆ«ìê°€ ì•„ë‹ˆë¼ 45ê°œì˜ í™•ë¥ ì„ ë±‰ì–´ëƒ„ ğŸ”¥
        # sigmoid: ê° ë²ˆí˜¸ë§ˆë‹¤ "ë‚˜ì˜¬ í™•ë¥ "ì„ 0~100%ë¡œ ë…ë¦½ì ìœ¼ë¡œ ê³„ì‚°
        Dense(45, activation='sigmoid') 
    ])
    
    # ì†ì‹¤ í•¨ìˆ˜ ë³€ê²½: binary_crossentropy (í™•ë¥  ë§ì¶”ê¸° ì „ìš© ì±„ì  ë°©ì‹)
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    
    # í•™ìŠµ
    model.fit(X, y, epochs=150, batch_size=32, verbose=0)
    
    # ì˜ˆì¸¡ (45ê°œì˜ í™•ë¥ ê°’ì´ ë‚˜ì˜´)
    prob_prediction = model.predict(last_window, verbose=0)[0]
    
    # í™•ë¥ ì´ ë†’ì€ ìˆœì„œëŒ€ë¡œ 6ê°œì˜ ë²ˆí˜¸ ì¸ë±ìŠ¤(ìœ„ì¹˜)ë¥¼ ì°¾ìŒ
    # argsortëŠ” ì‘ì€ ìˆœì„œëŒ€ë¡œ ì •ë ¬í•˜ë¯€ë¡œ, ë’¤ì—ì„œë¶€í„° 6ê°œë¥¼ ë½‘ìŒ (-6:)
    top_6_indices = prob_prediction.argsort()[-6:]
    
    # ì¸ë±ìŠ¤ëŠ” 0ë¶€í„° ì‹œì‘í•˜ë¯€ë¡œ +1ì„ í•´ì¤˜ì•¼ ì‹¤ì œ ë¡œë˜ ë²ˆí˜¸(1~45)ê°€ ë¨
    final_nums = np.sort(top_6_indices + 1)
    
    # í™•ë¥ ê°’ë„ ê°™ì´ ë³´ì—¬ì£¼ê¸° (ì–¼ë§ˆë‚˜ í™•ì‹ í•˜ëŠ”ì§€)
    confidence = prob_prediction[top_6_indices].mean() * 100
    
    print(f"ğŸ‘‰ Game {labels[i]} ì¶”ì²œ: {final_nums} (AI í™•ì‹ ë„: {confidence:.1f}%)")

print("\n" + "=" * 60)
input("âœ… í™•ë¥  ë¶„ì„ ì™„ë£Œ. ì¢…ë£Œí•˜ë ¤ë©´ ì—”í„° í‚¤ë¥¼ ëˆ„ë¥´ì„¸ìš”...")
```






