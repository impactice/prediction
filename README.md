# prediction


## ver1 

```
import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Input # Input ì¶”ê°€ë¨
import sys
import os

# ë¶ˆí•„ìš”í•œ ê²½ê³  ë©”ì‹œì§€ ë„ê¸° (ê¹”ë”í•œ í™”ë©´ì„ ìœ„í•´)
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
import warnings
warnings.filterwarnings('ignore')

# --- 1. ë°ì´í„° ì¤€ë¹„ ---
print("ğŸ“‚ ë¡œë˜ ë°ì´í„°ë¥¼ ì½ì–´ì˜µë‹ˆë‹¤...")

def read_csv_safe(filename):
    try:
        return pd.read_csv(filename, encoding='utf-8', header=None)
    except UnicodeDecodeError:
        return pd.read_csv(filename, encoding='cp949', header=None)

try:
    df1 = read_csv_safe('ë‹¹ì²¨(1~600).csv')
    df2 = read_csv_safe('ë‹¹ì²¨(601~1203).csv')
    
    data1 = df1.iloc[3:]
    data2 = df2.iloc[3:]
    full_df = pd.concat([data2, data1], axis=0)
    full_df = full_df[[1, 13, 14, 15, 16, 17, 18]]
    full_df.columns = ['Round', 'Num1', 'Num2', 'Num3', 'Num4', 'Num5', 'Num6']
    full_df = full_df.apply(pd.to_numeric, errors='coerce').dropna()
    full_df = full_df.sort_values('Round').reset_index(drop=True)
    
    numbers = full_df[['Num1', 'Num2', 'Num3', 'Num4', 'Num5', 'Num6']].values
    scaled_numbers = numbers / 45.0
    
    window_size = 5
    
    def create_dataset(data, window_size):
        X, y = [], []
        for i in range(len(data) - window_size):
            X.append(data[i : i + window_size])
            y.append(data[i + window_size])
        return np.array(X), np.array(y)
        
    X, y = create_dataset(scaled_numbers, window_size)
    last_window = scaled_numbers[-window_size:]
    last_window = last_window.reshape((1, window_size, 6))

    print(f"âœ… ë°ì´í„° ì½ê¸° ì„±ê³µ! ì´ {len(full_df)}íšŒì°¨ ë°ì´í„°ë¥¼ í™•ë³´í–ˆìŠµë‹ˆë‹¤.")

except Exception as e:
    print(f"\nâŒ [ì˜¤ë¥˜] ë°ì´í„°ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
    sys.exit()

# --- 2. 5ëª…ì˜ AI í•™ìŠµ ì‹œì‘ ---
print(f"\nğŸš€ 5ê°œì˜ ì„œë¡œ ë‹¤ë¥¸ AI ëª¨ë¸ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤... (ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”)")
print("=" * 60)

labels = ['A', 'B', 'C', 'D', 'E']

for i in range(5):
    print(f"\nğŸ¤– [AI ëª¨ë¸ {labels[i]} í•™ìŠµ ì¤‘...]")
    
    # ì—¬ê¸°ì„œ ê²½ê³ ë¥¼ ì—†ì• ê¸° ìœ„í•´ 'Input' ì¸µì„ ë”°ë¡œ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤.
    model = Sequential([
        Input(shape=(window_size, 6)), # ìµœì‹  ë°©ì‹
        LSTM(64, activation='relu'),
        Dense(6)
    ])
    model.compile(optimizer='adam', loss='mse')
    
    # í•™ìŠµ (verbose=0ìœ¼ë¡œ ì§€ì €ë¶„í•œ ë¡œê·¸ ìˆ¨ê¹€)
    model.fit(X, y, epochs=100, batch_size=16, verbose=0)
    
    prediction = model.predict(last_window, verbose=0)
    
    pred_nums = prediction * 45.0
    pred_nums = np.round(pred_nums).flatten().astype(int)
    pred_nums = np.clip(pred_nums, 1, 45)
    
    unique_nums = np.unique(pred_nums)
    while len(unique_nums) < 6:
        new_num = np.random.randint(1, 46)
        if new_num not in unique_nums:
            unique_nums = np.append(unique_nums, new_num)
    
    final_nums = np.sort(unique_nums)
    print(f"ğŸ‘‰ Game {labels[i]} ì¶”ì²œ ë²ˆí˜¸: {final_nums}")

print("\n" + "=" * 60)
input("âœ… ëª¨ë“  ì˜ˆì¸¡ì´ ëë‚¬ìŠµë‹ˆë‹¤. ì¢…ë£Œí•˜ë ¤ë©´ ì—”í„° í‚¤ë¥¼ ëˆ„ë¥´ì„¸ìš”...")
```


## ver2

### ì–‘ë°©í–¥(Bidirectional) LSTM ì‚¬ìš©:
ê¸°ì¡´: ê³¼ê±° $\rightarrow$ ë¯¸ë˜ ìˆœì„œë¡œë§Œ ê³µë¶€í–ˆìŠµë‹ˆë‹¤.  
ì—…ê·¸ë ˆì´ë“œ: ë¬¸ë§¥ì„ ë” ì˜ íŒŒì•…í•˜ê¸° ìœ„í•´ (ê³¼ê±° $\rightarrow$ ë¯¸ë˜)ì™€ (ë¯¸ë˜ $\rightarrow$ ê³¼ê±°) ì–‘ìª½ ë°©í–¥ìœ¼ë¡œ ë°ì´í„°ë¥¼ í›‘ì–´ë³´ê²Œ ë§Œë“­ë‹ˆë‹¤. (ë§ˆì¹˜ ì˜ì–´ ë…í•´ë¥¼ í•  ë•Œ ì•ë’¤ ë¬¸ë§¥ì„ ë‹¤ ë³´ëŠ” ê²ƒê³¼ ê°™ìŠµë‹ˆë‹¤.)

### ì¸µ(Layer) ë” ìŒ“ê¸° (Deep Learning):
ê¸°ì¡´: ë‡Œì„¸í¬ ì¸µì´ 1ê°œì˜€ìŠµë‹ˆë‹¤.  
ì—…ê·¸ë ˆì´ë“œ: LSTM ì¸µì„ 2~3ê°œë¡œ ê²¹ì³ì„œ ìŒ“ìŠµë‹ˆë‹¤. 1ì¸µì€ ë‹¨ìˆœí•œ íŒ¨í„´, 2ì¸µì€ ë³µì¡í•œ íŒ¨í„´ì„ ë¶„ì„í•˜ë„ë¡ **"ê¹Šì€ ì‚¬ê³ "**ë¥¼ í•˜ê²Œ ë§Œë“­ë‹ˆë‹¤.

### í•™ìŠµ íšŸìˆ˜ì™€ ë‡Œì„¸í¬ ëŠ˜ë¦¬ê¸°:
ê¸°ì¡´ 64ê°œì˜€ë˜ ë‰´ëŸ°(Neuron)ì„ 128ê°œ ë˜ëŠ” 256ê°œë¡œ ëŠ˜ë¦¬ê³ , í•™ìŠµ ë°˜ë³µ íšŸìˆ˜(Epoch)ë„ ëŠ˜ë ¤ì„œ ë” ì§‘ìš”í•˜ê²Œ íŒ¨í„´ì„ ì°¾ê²Œ í•©ë‹ˆë‹¤.

```
import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Input, Bidirectional, Dropout
import sys
import os

# 1. í™˜ê²½ ì„¤ì •
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
import warnings
warnings.filterwarnings('ignore')

print("ğŸ“‚ [Proë²„ì „] ë³€ê²½ëœ ë°ì´í„° êµ¬ì¡°ì— ë§ì¶° ë¡œë”© ì¤‘ì…ë‹ˆë‹¤...")

# 2. ë°ì´í„° ì½ê¸°
def read_csv_safe(filename):
    try:
        return pd.read_csv(filename, encoding='utf-8', header=None)
    except UnicodeDecodeError:
        return pd.read_csv(filename, encoding='cp949', header=None)

try:
    df1 = read_csv_safe('ë‹¹ì²¨(1~600).csv')
    df2 = read_csv_safe('ë‹¹ì²¨(601~1203).csv')
    
    # 3ì¤„ í—¤ë” ê±´ë„ˆë›°ê¸° (ì´ê±´ êµ¬ì¡°ê°€ ìœ ì§€ë˜ì—ˆìœ¼ë¯€ë¡œ ê·¸ëŒ€ë¡œ ë‘¡ë‹ˆë‹¤)
    data1 = df1.iloc[3:]
    data2 = df2.iloc[3:]
    
    full_df = pd.concat([data2, data1], axis=0)
    
    # ğŸ”¥ [í•µì‹¬ ìˆ˜ì •] ë³€ê²½ëœ íŒŒì¼ ë‚´ìš©ì— ë§ê²Œ ì—´ ë²ˆí˜¸ ìˆ˜ì • ğŸ”¥
    # ê¸°ì¡´: [1, 13, 14, 15, 16, 17, 18]
    # ë³€ê²½: [1, 2, 3, 4, 5, 6, 7] (ë¹ˆ ì¹¸ ì—†ì´ ë°”ë¡œ ì˜†ì— ë¶™ì–´ ìˆìŒ)
    full_df = full_df[[1, 2, 3, 4, 5, 6, 7]]
    
    full_df.columns = ['Round', 'Num1', 'Num2', 'Num3', 'Num4', 'Num5', 'Num6']
    full_df = full_df.apply(pd.to_numeric, errors='coerce').dropna()
    full_df = full_df.sort_values('Round').reset_index(drop=True)
    
    # ì •ê·œí™”
    numbers = full_df[['Num1', 'Num2', 'Num3', 'Num4', 'Num5', 'Num6']].values
    scaled_numbers = numbers / 45.0
    
    window_size = 10 
    
    def create_dataset(data, window_size):
        X, y = [], []
        for i in range(len(data) - window_size):
            X.append(data[i : i + window_size])
            y.append(data[i + window_size])
        return np.array(X), np.array(y)
        
    X, y = create_dataset(scaled_numbers, window_size)
    last_window = scaled_numbers[-window_size:]
    last_window = last_window.reshape((1, window_size, 6))

    print(f"âœ… ë°ì´í„° ë¡œë”© ì„±ê³µ! ì´ {len(full_df)}íšŒì°¨ (ì—´ êµ¬ì¡° ìë™ ë³´ì • ì™„ë£Œ)")
    print(f"âœ… ë¶„ì„ ê¹Šì´: ê³¼ê±° {window_size}íšŒì°¨ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì˜ˆì¸¡")

except Exception as e:
    print(f"\nâŒ ë°ì´í„° êµ¬ì¡° ì˜¤ë¥˜: {e}")
    print("ğŸ‘‰ ì—‘ì…€ ë‚´ìš©ì´ ë°”ë€Œë©´ì„œ ì—´ ë²ˆí˜¸ê°€ ë‹¬ë¼ì§„ ê²ƒ ê°™ìŠµë‹ˆë‹¤. íŒŒì¼ ë‚´ìš©ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    sys.exit()

# 3. ê³ ì„±ëŠ¥ AI ëª¨ë¸ ì„¤ê³„ (ê²€ì‚¬ ë°©ë²• ë³€ê²½ X)
print(f"\nğŸš€ [Deep Learning] ê³ ì„±ëŠ¥ ì˜ˆì¸¡ ëª¨ë¸ ê°€ë™ ì‹œì‘...")
print("=" * 60)

labels = ['A', 'B', 'C', 'D', 'E']

for i in range(5):
    print(f"\nğŸ§  [AI ëª¨ë¸ {labels[i]} ì‹¬ì¸µ í•™ìŠµ ì¤‘...]")
    
    model = Sequential([
        Input(shape=(window_size, 6)),
        # ì–‘ë°©í–¥ LSTM
        Bidirectional(LSTM(128, return_sequences=True)),
        Dropout(0.2),
        # ì‹¬ì¸µ LSTM
        LSTM(64, return_sequences=False),
        Dropout(0.2),
        # ê²°ê³¼ ì¶œë ¥
        Dense(64, activation='relu'),
        Dense(6)
    ])
    
    model.compile(optimizer='adam', loss='mse')
    
    # í•™ìŠµ (150íšŒ ë°˜ë³µ)
    model.fit(X, y, epochs=150, batch_size=16, verbose=0)
    
    # ì˜ˆì¸¡
    prediction = model.predict(last_window, verbose=0)
    
    pred_nums = prediction * 45.0
    pred_nums = np.round(pred_nums).flatten().astype(int)
    pred_nums = np.clip(pred_nums, 1, 45)
    
    unique_nums = np.unique(pred_nums)
    while len(unique_nums) < 6:
        new_num = np.random.randint(1, 46)
        if new_num not in unique_nums:
            unique_nums = np.append(unique_nums, new_num)
    
    final_nums = np.sort(unique_nums)
    print(f"ğŸ‘‰ Game {labels[i]} (Deep) ì¶”ì²œ: {final_nums}")

print("\n" + "=" * 60)
input("âœ… ê³ ì„±ëŠ¥ ì˜ˆì¸¡ ì™„ë£Œ. ì¢…ë£Œí•˜ë ¤ë©´ ì—”í„° í‚¤ë¥¼ ëˆ„ë¥´ì„¸ìš”...")
```
- íŒŒì¼ ëª¨ìŠµë„ ë³€ê²½ì´ ë˜ì—ˆìŒ 


## ver3
Window Sizeë¥¼ 260(ì•½ 5ë…„ì¹˜)ë¥¼ ë³´ê³  ì˜ˆì¸¡
```
import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Input, Bidirectional, Dropout
import sys
import os

# 1. í™˜ê²½ ì„¤ì •
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
import warnings
warnings.filterwarnings('ignore')

print("ğŸ“‚ [Ultra Long-Term] ê³¼ê±° 260íšŒ(ì•½ 5ë…„) ë°ì´í„°ë¥¼ í†µì§¸ë¡œ ë¶„ì„í•©ë‹ˆë‹¤...")

# 2. ë°ì´í„° ì½ê¸°
def read_csv_safe(filename):
    try:
        return pd.read_csv(filename, encoding='utf-8', header=None)
    except UnicodeDecodeError:
        return pd.read_csv(filename, encoding='cp949', header=None)

try:
    df1 = read_csv_safe('ë‹¹ì²¨(1~600).csv')
    df2 = read_csv_safe('ë‹¹ì²¨(601~1203).csv')
    
    # í—¤ë” 3ì¤„ ì œê±°
    data1 = df1.iloc[3:]
    data2 = df2.iloc[3:]
    
    full_df = pd.concat([data2, data1], axis=0)
    
    # ìˆ˜ì •ëœ íŒŒì¼ êµ¬ì¡° ë°˜ì˜ (1~7ì—´)
    full_df = full_df[[1, 2, 3, 4, 5, 6, 7]]
    full_df.columns = ['Round', 'Num1', 'Num2', 'Num3', 'Num4', 'Num5', 'Num6']
    full_df = full_df.apply(pd.to_numeric, errors='coerce').dropna()
    full_df = full_df.sort_values('Round').reset_index(drop=True)
    
    # ì •ê·œí™”
    numbers = full_df[['Num1', 'Num2', 'Num3', 'Num4', 'Num5', 'Num6']].values
    scaled_numbers = numbers / 45.0
    
    # ğŸ”¥ [í•µì‹¬ ë³€ê²½] Window Sizeë¥¼ 260(ì•½ 5ë…„)ìœ¼ë¡œ ì„¤ì • ğŸ”¥
    # ë„ˆë¬´ í¬ë©´(ì˜ˆ: 1000) í•™ìŠµí•  ë°ì´í„°ê°€ ë¶€ì¡±í•´ì§€ë¯€ë¡œ, 260 ì •ë„ê°€ ì ë‹¹í•œ 'ìµœëŒ€ì¹˜'ì…ë‹ˆë‹¤.
    window_size = 260
    
    def create_dataset(data, window_size):
        X, y = [], []
        for i in range(len(data) - window_size):
            X.append(data[i : i + window_size])
            y.append(data[i + window_size])
        return np.array(X), np.array(y)
        
    X, y = create_dataset(scaled_numbers, window_size)
    last_window = scaled_numbers[-window_size:]
    last_window = last_window.reshape((1, window_size, 6))

    print(f"âœ… ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ! ì´ {len(full_df)}íšŒì°¨")
    print(f"âœ… ë¶„ì„ ë²”ìœ„: í•œ ë²ˆì— ê³¼ê±° {window_size}ì£¼(ì•½ 5ë…„)ì˜ íë¦„ì„ ë´…ë‹ˆë‹¤.")
    print(f"âœ… í•™ìŠµ ê°€ëŠ¥ ì˜ˆì œ ìˆ˜: {len(X)}ê°œ (ì¶©ë¶„í•©ë‹ˆë‹¤!)")

except Exception as e:
    print(f"\nâŒ ì˜¤ë¥˜: {e}")
    sys.exit()

# 3. ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡
print(f"\nğŸš€ [Super Long-Term] 5ë…„ì¹˜ íŒ¨í„´ ì •ë°€ ë¶„ì„ ì‹œì‘...")
print("=" * 60)

labels = ['A', 'B', 'C', 'D', 'E']

for i in range(5):
    print(f"\nğŸ§  [AI ëª¨ë¸ {labels[i]} í•™ìŠµ ì¤‘... (ì‹œê°„ì´ ì¢€ ê±¸ë¦½ë‹ˆë‹¤)]")
    
    model = Sequential([
        Input(shape=(window_size, 6)),
        # 5ë…„ì¹˜ ê¸´ ë°ì´í„°ë¥¼ ê¹Œë¨¹ì§€ ì•Šê²Œ LSTM ë‰´ëŸ°ì„ 256ê°œë¡œ ëŒ€í­ ëŠ˜ë¦¼
        Bidirectional(LSTM(256, return_sequences=True)),
        Dropout(0.3),
        
        LSTM(128, return_sequences=False),
        Dropout(0.3),
        
        Dense(128, activation='relu'),
        Dense(6)
    ])
    
    model.compile(optimizer='adam', loss='mse')
    
    # ë°ì´í„°ê°€ ê¸¸ì–´ì„œ í•™ìŠµ íšŸìˆ˜(epochs)ë¥¼ 300íšŒë¡œ ì„¤ì •
    model.fit(X, y, epochs=300, batch_size=64, verbose=0)
    
    prediction = model.predict(last_window, verbose=0)
    
    pred_nums = prediction * 45.0
    pred_nums = np.round(pred_nums).flatten().astype(int)
    pred_nums = np.clip(pred_nums, 1, 45)
    
    unique_nums = np.unique(pred_nums)
    while len(unique_nums) < 6:
        new_num = np.random.randint(1, 46)
        if new_num not in unique_nums:
            unique_nums = np.append(unique_nums, new_num)
    
    final_nums = np.sort(unique_nums)
    print(f"ğŸ‘‰ Game {labels[i]} (5ë…„ ë¶„ì„) ì¶”ì²œ: {final_nums}")

print("\n" + "=" * 60)
input("âœ… ì˜ˆì¸¡ ì™„ë£Œ. ì¢…ë£Œí•˜ë ¤ë©´ ì—”í„° í‚¤ë¥¼ ëˆ„ë¥´ì„¸ìš”...")
```

