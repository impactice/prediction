# prediction


## ver1 

```
import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Input # Input ì¶”ê°€ë¨
import sys
import os

# ë¶ˆí•„ìš”í•œ ê²½ê³  ë©”ì‹œì§€ ë„ê¸° (ê¹”ë”í•œ í™”ë©´ì„ ìœ„í•´)
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
import warnings
warnings.filterwarnings('ignore')

# --- 1. ë°ì´í„° ì¤€ë¹„ ---
print("ğŸ“‚ ë¡œë˜ ë°ì´í„°ë¥¼ ì½ì–´ì˜µë‹ˆë‹¤...")

def read_csv_safe(filename):
    try:
        return pd.read_csv(filename, encoding='utf-8', header=None)
    except UnicodeDecodeError:
        return pd.read_csv(filename, encoding='cp949', header=None)

try:
    df1 = read_csv_safe('ë‹¹ì²¨(1~600).csv')
    df2 = read_csv_safe('ë‹¹ì²¨(601~1203).csv')
    
    data1 = df1.iloc[3:]
    data2 = df2.iloc[3:]
    full_df = pd.concat([data2, data1], axis=0)
    full_df = full_df[[1, 13, 14, 15, 16, 17, 18]]
    full_df.columns = ['Round', 'Num1', 'Num2', 'Num3', 'Num4', 'Num5', 'Num6']
    full_df = full_df.apply(pd.to_numeric, errors='coerce').dropna()
    full_df = full_df.sort_values('Round').reset_index(drop=True)
    
    numbers = full_df[['Num1', 'Num2', 'Num3', 'Num4', 'Num5', 'Num6']].values
    scaled_numbers = numbers / 45.0
    
    window_size = 5
    
    def create_dataset(data, window_size):
        X, y = [], []
        for i in range(len(data) - window_size):
            X.append(data[i : i + window_size])
            y.append(data[i + window_size])
        return np.array(X), np.array(y)
        
    X, y = create_dataset(scaled_numbers, window_size)
    last_window = scaled_numbers[-window_size:]
    last_window = last_window.reshape((1, window_size, 6))

    print(f"âœ… ë°ì´í„° ì½ê¸° ì„±ê³µ! ì´ {len(full_df)}íšŒì°¨ ë°ì´í„°ë¥¼ í™•ë³´í–ˆìŠµë‹ˆë‹¤.")

except Exception as e:
    print(f"\nâŒ [ì˜¤ë¥˜] ë°ì´í„°ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
    sys.exit()

# --- 2. 5ëª…ì˜ AI í•™ìŠµ ì‹œì‘ ---
print(f"\nğŸš€ 5ê°œì˜ ì„œë¡œ ë‹¤ë¥¸ AI ëª¨ë¸ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤... (ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”)")
print("=" * 60)

labels = ['A', 'B', 'C', 'D', 'E']

for i in range(5):
    print(f"\nğŸ¤– [AI ëª¨ë¸ {labels[i]} í•™ìŠµ ì¤‘...]")
    
    # ì—¬ê¸°ì„œ ê²½ê³ ë¥¼ ì—†ì• ê¸° ìœ„í•´ 'Input' ì¸µì„ ë”°ë¡œ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤.
    model = Sequential([
        Input(shape=(window_size, 6)), # ìµœì‹  ë°©ì‹
        LSTM(64, activation='relu'),
        Dense(6)
    ])
    model.compile(optimizer='adam', loss='mse')
    
    # í•™ìŠµ (verbose=0ìœ¼ë¡œ ì§€ì €ë¶„í•œ ë¡œê·¸ ìˆ¨ê¹€)
    model.fit(X, y, epochs=100, batch_size=16, verbose=0)
    
    prediction = model.predict(last_window, verbose=0)
    
    pred_nums = prediction * 45.0
    pred_nums = np.round(pred_nums).flatten().astype(int)
    pred_nums = np.clip(pred_nums, 1, 45)
    
    unique_nums = np.unique(pred_nums)
    while len(unique_nums) < 6:
        new_num = np.random.randint(1, 46)
        if new_num not in unique_nums:
            unique_nums = np.append(unique_nums, new_num)
    
    final_nums = np.sort(unique_nums)
    print(f"ğŸ‘‰ Game {labels[i]} ì¶”ì²œ ë²ˆí˜¸: {final_nums}")

print("\n" + "=" * 60)
input("âœ… ëª¨ë“  ì˜ˆì¸¡ì´ ëë‚¬ìŠµë‹ˆë‹¤. ì¢…ë£Œí•˜ë ¤ë©´ ì—”í„° í‚¤ë¥¼ ëˆ„ë¥´ì„¸ìš”...")
```


## ver2

### ì–‘ë°©í–¥(Bidirectional) LSTM ì‚¬ìš©:
ê¸°ì¡´: ê³¼ê±° $\rightarrow$ ë¯¸ë˜ ìˆœì„œë¡œë§Œ ê³µë¶€í–ˆìŠµë‹ˆë‹¤.  
ì—…ê·¸ë ˆì´ë“œ: ë¬¸ë§¥ì„ ë” ì˜ íŒŒì•…í•˜ê¸° ìœ„í•´ (ê³¼ê±° $\rightarrow$ ë¯¸ë˜)ì™€ (ë¯¸ë˜ $\rightarrow$ ê³¼ê±°) ì–‘ìª½ ë°©í–¥ìœ¼ë¡œ ë°ì´í„°ë¥¼ í›‘ì–´ë³´ê²Œ ë§Œë“­ë‹ˆë‹¤. (ë§ˆì¹˜ ì˜ì–´ ë…í•´ë¥¼ í•  ë•Œ ì•ë’¤ ë¬¸ë§¥ì„ ë‹¤ ë³´ëŠ” ê²ƒê³¼ ê°™ìŠµë‹ˆë‹¤.)

### ì¸µ(Layer) ë” ìŒ“ê¸° (Deep Learning):
ê¸°ì¡´: ë‡Œì„¸í¬ ì¸µì´ 1ê°œì˜€ìŠµë‹ˆë‹¤.  
ì—…ê·¸ë ˆì´ë“œ: LSTM ì¸µì„ 2~3ê°œë¡œ ê²¹ì³ì„œ ìŒ“ìŠµë‹ˆë‹¤. 1ì¸µì€ ë‹¨ìˆœí•œ íŒ¨í„´, 2ì¸µì€ ë³µì¡í•œ íŒ¨í„´ì„ ë¶„ì„í•˜ë„ë¡ **"ê¹Šì€ ì‚¬ê³ "**ë¥¼ í•˜ê²Œ ë§Œë“­ë‹ˆë‹¤.

### í•™ìŠµ íšŸìˆ˜ì™€ ë‡Œì„¸í¬ ëŠ˜ë¦¬ê¸°:ê¸°ì¡´ 64ê°œì˜€ë˜ ë‰´ëŸ°(Neuron)ì„ 128ê°œ ë˜ëŠ” 256ê°œë¡œ ëŠ˜ë¦¬ê³ , í•™ìŠµ ë°˜ë³µ íšŸìˆ˜(Epoch)ë„ ëŠ˜ë ¤ì„œ ë” ì§‘ìš”í•˜ê²Œ íŒ¨í„´ì„ ì°¾ê²Œ í•©ë‹ˆë‹¤.


















